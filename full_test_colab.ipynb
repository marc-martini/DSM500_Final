{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5PJY6yUOPrS",
        "outputId": "f46c226b-b1b3-4bd6-f641-ef893fc8998e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n"
          ]
        }
      ],
      "source": [
        "# ensure basic colab requiremetns inplace\n",
        "!pip install einops\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhBpwcUkgAn4",
        "outputId": "e099f76d-889f-41e2-df55-10aaca6cb3f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/full_test\n",
            " data\t\t   layers\t\t\t\t\t\t\t     results.ipynb\n",
            " data_provider\t  'MM DSM 500 - Final Project draft 2.docx'\t\t\t     results..xlsx\n",
            " embed\t\t  'MM DSM 500 - Final Project (working main) (AutoRecovered).docx'   run_test.py\n",
            " exp\t\t   models\t\t\t\t\t\t\t     scripts\n",
            " full_test.ipynb   requirements.txt\t\t\t\t\t\t     utils\n",
            " full_test.py\t   results\n"
          ]
        }
      ],
      "source": [
        "# connect google drive for full files and results transfer\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!cp -r /content/gdrive/MyDrive/full_test/ /content\n",
        "%cd full_test\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDtypt2XoYXt"
      },
      "outputs": [],
      "source": [
        "# import requirements \n",
        "import os\n",
        "from exp.exp_main import Exp_Main\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "from utils.set_args import set_args\n",
        "\n",
        "# func to handle the full test in colab\n",
        "def run_test_colab(model_name='Informer', data_name='ECL', single_pred=96, multi_test=True, multi_pred=[96, 192, 336, 720]):\n",
        "    # start time\n",
        "    full_start_time = time.time()\n",
        "\n",
        "    root_path='./data/' # data root path\n",
        "    random_seed=2024 # random seed for reproduciblity\n",
        "\n",
        "\n",
        "    # get basic varibles for function\n",
        "    model_name = model_name\n",
        "    data_name = data_name\n",
        "    data_path = data_name + '.csv'\n",
        "\n",
        "\n",
        "    # get model num from model dict\n",
        "    models = {'Informer' : 'Model-1',\n",
        "              'PatchTST' : 'Model-2',\n",
        "              'DLinear' : 'Model-3',\n",
        "              'NLinear' : 'Model-4',\n",
        "              'FEDformer' : 'Model-5',\n",
        "              'Linear_PatchTST' : 'Model-6',\n",
        "              'PatchFED' : 'Model-7',\n",
        "              'RevIN_PatchTST' : 'Model-8',\n",
        "              'RevIN_Linear' : 'Model-9'}\n",
        "\n",
        "    model_num = models[model_name]\n",
        "\n",
        "    # get model ID name\n",
        "    if data_name == 'ECL':\n",
        "        model_id_name='Electricity' # model id name\n",
        "    elif data_name == 'PJM':\n",
        "        model_id_name='PJM' # model id name\n",
        "\n",
        "    # set target\n",
        "\n",
        "    if data_name == 'ECL':\n",
        "        target ='OT'\n",
        "    elif data_name == \"PJM\":\n",
        "        target ='FE'\n",
        "\n",
        "    # prediction types and lengths\n",
        "    multi_test = multi_test\n",
        "    single_pred = single_pred\n",
        "    multi_pred = multi_pred\n",
        "\n",
        "    print(data_name, model_id_name)\n",
        "\n",
        "    # create the exprimental class # from exp_main.py\n",
        "    Exp = Exp_Main\n",
        "\n",
        "    # copy results if exist in to drive as backup\n",
        "    !cp -r /content/full_test/results /content/gdrive/MyDrive/full_test/\n",
        "\n",
        "    # run the test check if multi or single test\n",
        "    if multi_test:\n",
        "        for seq_len in [96]: #192, 336, 720 other options for seq len\n",
        "            for pred_len in multi_pred:\n",
        "\n",
        "                seq_len = seq_len\n",
        "                # start time\n",
        "                start_pred_len = time.time()\n",
        "\n",
        "                # set training parameters\n",
        "                pred_len = pred_len\n",
        "\n",
        "                # get args and setting define based on input variables \n",
        "                args, setting = set_args(model_num, data_name, seq_len, model_name, root_path, data_path, model_id_name, random_seed, pred_len, target, full_start_time)\n",
        "\n",
        "                print(setting)\n",
        "                # results path\n",
        "                folder_path = os.path.join('./results/', setting)\n",
        "                if not os.path.exists(folder_path):\n",
        "                    os.makedirs(folder_path)\n",
        "                test_file_name = folder_path + '/Model training and test.txt'\n",
        "                test_f = open(test_file_name, 'a')\n",
        "\n",
        "\n",
        "                # set experiments into the experiment class\n",
        "                exp = Exp(args)\n",
        "\n",
        "                # train\n",
        "                print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
        "                exp.train(setting)\n",
        "\n",
        "                # test\n",
        "                print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "                exp.test(setting)\n",
        "\n",
        "\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "                # pred run tim\n",
        "                end_pred_len = time.time()\n",
        "                elapsed_pred_len = end_pred_len - start_pred_len\n",
        "\n",
        "                # show outputs of time \n",
        "                print(\"Length of train/test for pred length {} : {} sec or {} mins \", pred_len, elapsed_pred_len, elapsed_pred_len/60)\n",
        "                test_f = open(test_file_name, 'a')\n",
        "                test_f.write(\"\\nTime elapsed (s): {} \\n\".format(pred_len))\n",
        "                test_f.write(\"Time elapsed (s): {} \\n\".format(elapsed_pred_len/60))\n",
        "                test_f.write(\"Time elapsed (s): {} \\n\".format((elapsed_pred_len/60)/60))\n",
        "\n",
        "                # backup results \n",
        "                !cp -r /content/full_test/results /content/gdrive/MyDrive/full_test/\n",
        "            # clear cache for multi runs \n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    else:\n",
        "            seq_len = 96 # default value\n",
        "            # set training parameters\n",
        "            pred_len = single_pred\n",
        "\n",
        "            # get args and setting define based on input variables \n",
        "            args, setting = set_args(model_num, data_name, seq_len, model_name, root_path, data_path, model_id_name, random_seed, pred_len, target, full_start_time)\n",
        "\n",
        "            print(setting)\n",
        "            # results path\n",
        "            folder_path = os.path.join('./results/', setting)\n",
        "            if not os.path.exists(folder_path):\n",
        "                os.makedirs(folder_path)\n",
        "            test_file_name = folder_path + '/Model training and test.txt'\n",
        "            test_f = open(test_file_name, 'a')\n",
        "            test_f.write('\\n')\n",
        "\n",
        "            # set experiments\n",
        "            exp = Exp(args)\n",
        "\n",
        "            # train\n",
        "            print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
        "            exp.train(setting)\n",
        "\n",
        "            # test\n",
        "            print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "            exp.test(setting)\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    # full time\n",
        "    full_end = time.time()\n",
        "    full_elapsed = full_end - full_start_time\n",
        "    # show outputs of time \n",
        "    print(\"Time elapsed (s): {} \".format(full_elapsed))\n",
        "    print(\"Time elapsed (mins): {} \".format(full_elapsed/60))\n",
        "    print(\"Time elapsed (hrs): {}\".format((full_elapsed/60)/60))\n",
        "    test_f = open(test_file_name, 'a')\n",
        "    test_f.write(\"\\nTime elapsed (s): {} \\n\".format(full_elapsed))\n",
        "    test_f.write(\"Time elapsed (s): {} \\n\".format(full_elapsed/60))\n",
        "    test_f.write(\"Time elapsed (s): {} \\n\".format((full_elapsed/60)/60))\n",
        "    # back up results\n",
        "    !cp -r /content/full_test/results /content/gdrive/MyDrive/full_test/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-N6Gs-zGAdB",
        "outputId": "e97509d1-88d1-4fba-ff8e-a7c553e38afb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ECL Electricity\n",
            "Linear_PatchTST_Model-6_ECL_ftM_sl720_ll48_pl96_dm512_nh8_el2_dl1_df2048_atprob_fc3_ebtimeF_dtTrue_mxNone_Exp_0\n",
            "Linear_PatchTST_Model-6_ECL_ftM_sl720_ll48_pl96_dm512_nh8_el2_dl1_df2048_atprob_fc3_ebtimeF_dtTrue_mxNone_Exp_0\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : Linear_PatchTST_Model-6_ECL_ftM_sl720_ll48_pl96_dm512_nh8_el2_dl1_df2048_atprob_fc3_ebtimeF_dtTrue_mxNone_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 17597\n",
            "val 2537\n",
            "test 5165\n",
            "\titers: 100, epoch: 1 | loss: 0.2021187\n",
            "\tspeed: 0.1801s/iter; left time: 1959.6805s\n",
            "\titers: 200, epoch: 1 | loss: 0.2147429\n",
            "\tspeed: 0.3115s/iter; left time: 3358.1575s\n",
            "\titers: 300, epoch: 1 | loss: 0.1734799\n",
            "\tspeed: 0.4419s/iter; left time: 4719.7550s\n",
            "\titers: 400, epoch: 1 | loss: 0.1676506\n",
            "\tspeed: 0.5704s/iter; left time: 6035.2946s\n",
            "\titers: 500, epoch: 1 | loss: 0.1548763\n",
            "\tspeed: 0.6966s/iter; left time: 7300.9911s\n",
            "Epoch: 1 cost time: 71.62498784065247\n",
            "Epoch: 1, Steps: 549 | Train Loss: 0.2022204 Vali Loss: 0.1289941 Test Loss: 0.1513274\n",
            "Validation loss decreased (inf --> 0.128994).  Saving model ...\n",
            "Updating learning rate to 0.0001\n",
            "\titers: 100, epoch: 2 | loss: 0.1416691\n",
            "\tspeed: 1.1430s/iter; left time: 11809.9688s\n",
            "\titers: 200, epoch: 2 | loss: 0.1470491\n",
            "\tspeed: 1.2737s/iter; left time: 13032.8832s\n",
            "\titers: 300, epoch: 2 | loss: 0.1452762\n",
            "\tspeed: 1.4037s/iter; left time: 14222.2586s\n",
            "\titers: 400, epoch: 2 | loss: 0.1610036\n",
            "\tspeed: 1.5322s/iter; left time: 15370.8347s\n",
            "\titers: 500, epoch: 2 | loss: 0.1449826\n",
            "\tspeed: 1.6588s/iter; left time: 16475.0827s\n",
            "Epoch: 2 cost time: 71.61912131309509\n",
            "Epoch: 2, Steps: 549 | Train Loss: 0.1473822 Vali Loss: 0.1213198 Test Loss: 0.1424737\n",
            "Validation loss decreased (0.128994 --> 0.121320).  Saving model ...\n",
            "Updating learning rate to 5e-05\n",
            "\titers: 100, epoch: 3 | loss: 0.1224110\n",
            "\tspeed: 2.1018s/iter; left time: 20561.5110s\n",
            "\titers: 200, epoch: 3 | loss: 0.1281893\n",
            "\tspeed: 2.2316s/iter; left time: 21608.4620s\n",
            "\titers: 300, epoch: 3 | loss: 0.1221348\n",
            "\tspeed: 2.3618s/iter; left time: 22633.2531s\n",
            "\titers: 400, epoch: 3 | loss: 0.1253169\n",
            "\tspeed: 2.4914s/iter; left time: 23626.1929s\n",
            "\titers: 500, epoch: 3 | loss: 0.1162004\n",
            "\tspeed: 2.6195s/iter; left time: 24578.5855s\n",
            "Epoch: 3 cost time: 71.73648834228516\n",
            "Epoch: 3, Steps: 549 | Train Loss: 0.1379506 Vali Loss: 0.1211936 Test Loss: 0.1404773\n",
            "Validation loss decreased (0.121320 --> 0.121194).  Saving model ...\n",
            "Updating learning rate to 2.5e-05\n",
            "\titers: 100, epoch: 4 | loss: 0.1416079\n",
            "\tspeed: 3.0661s/iter; left time: 28312.6407s\n",
            "\titers: 200, epoch: 4 | loss: 0.1623109\n",
            "\tspeed: 3.1960s/iter; left time: 29192.2774s\n",
            "\titers: 300, epoch: 4 | loss: 0.1382829\n",
            "\tspeed: 3.3263s/iter; left time: 30049.4562s\n",
            "\titers: 400, epoch: 4 | loss: 0.1350915\n",
            "\tspeed: 3.4558s/iter; left time: 30874.1015s\n",
            "\titers: 500, epoch: 4 | loss: 0.1410987\n",
            "\tspeed: 3.5834s/iter; left time: 31655.4802s\n",
            "Epoch: 4 cost time: 71.61918139457703\n",
            "Epoch: 4, Steps: 549 | Train Loss: 0.1355098 Vali Loss: 0.1143437 Test Loss: 0.1357475\n",
            "Validation loss decreased (0.121194 --> 0.114344).  Saving model ...\n",
            "Updating learning rate to 1.25e-05\n",
            "\titers: 100, epoch: 5 | loss: 0.1342060\n",
            "\tspeed: 4.0290s/iter; left time: 34991.7018s\n",
            "\titers: 200, epoch: 5 | loss: 0.1390200\n",
            "\tspeed: 4.1582s/iter; left time: 35697.9700s\n",
            "\titers: 300, epoch: 5 | loss: 0.1246703\n",
            "\tspeed: 4.2880s/iter; left time: 36383.9499s\n",
            "\titers: 400, epoch: 5 | loss: 0.1276976\n",
            "\tspeed: 4.4174s/iter; left time: 37039.7054s\n",
            "\titers: 500, epoch: 5 | loss: 0.1572187\n",
            "\tspeed: 4.5449s/iter; left time: 37654.1032s\n",
            "Epoch: 5 cost time: 71.5030791759491\n",
            "Epoch: 5, Steps: 549 | Train Loss: 0.1340372 Vali Loss: 0.1130379 Test Loss: 0.1341603\n",
            "Validation loss decreased (0.114344 --> 0.113038).  Saving model ...\n",
            "Updating learning rate to 6.25e-06\n",
            "\titers: 100, epoch: 6 | loss: 0.1282682\n",
            "\tspeed: 4.9896s/iter; left time: 40595.3417s\n",
            "\titers: 200, epoch: 6 | loss: 0.1394308\n",
            "\tspeed: 5.1184s/iter; left time: 41131.1611s\n",
            "\titers: 300, epoch: 6 | loss: 0.1197326\n",
            "\tspeed: 5.2484s/iter; left time: 41651.1233s\n",
            "\titers: 400, epoch: 6 | loss: 0.1612800\n",
            "\tspeed: 5.3780s/iter; left time: 42141.9699s\n",
            "\titers: 500, epoch: 6 | loss: 0.1449387\n",
            "\tspeed: 5.5061s/iter; left time: 42594.8471s\n",
            "Epoch: 6 cost time: 71.55057621002197\n",
            "Epoch: 6, Steps: 549 | Train Loss: 0.1333552 Vali Loss: 0.1121775 Test Loss: 0.1332526\n",
            "Validation loss decreased (0.113038 --> 0.112177).  Saving model ...\n",
            "Updating learning rate to 3.125e-06\n",
            "\titers: 100, epoch: 7 | loss: 0.1378661\n",
            "\tspeed: 5.9529s/iter; left time: 45164.7067s\n",
            "\titers: 200, epoch: 7 | loss: 0.1276098\n",
            "\tspeed: 6.0828s/iter; left time: 45542.0822s\n",
            "\titers: 300, epoch: 7 | loss: 0.1071845\n",
            "\tspeed: 6.2127s/iter; left time: 45893.3442s\n",
            "\titers: 400, epoch: 7 | loss: 0.1372583\n",
            "\tspeed: 6.3418s/iter; left time: 46212.4006s\n",
            "\titers: 500, epoch: 7 | loss: 0.1197513\n",
            "\tspeed: 6.4691s/iter; left time: 46493.0831s\n",
            "Epoch: 7 cost time: 71.68112897872925\n",
            "Epoch: 7, Steps: 549 | Train Loss: 0.1328819 Vali Loss: 0.1119434 Test Loss: 0.1329700\n",
            "Validation loss decreased (0.112177 --> 0.111943).  Saving model ...\n",
            "Updating learning rate to 1.5625e-06\n",
            "\titers: 100, epoch: 8 | loss: 0.1223519\n",
            "\tspeed: 6.9163s/iter; left time: 48676.8999s\n",
            "\titers: 200, epoch: 8 | loss: 0.1238825\n",
            "\tspeed: 7.0459s/iter; left time: 48884.1630s\n",
            "\titers: 300, epoch: 8 | loss: 0.1333752\n",
            "\tspeed: 7.1760s/iter; left time: 49069.5922s\n",
            "\titers: 400, epoch: 8 | loss: 0.1240041\n",
            "\tspeed: 7.3045s/iter; left time: 49217.4053s\n",
            "\titers: 500, epoch: 8 | loss: 0.1389547\n",
            "\tspeed: 7.4307s/iter; left time: 49325.2089s\n",
            "Epoch: 8 cost time: 71.48696279525757\n",
            "Epoch: 8, Steps: 549 | Train Loss: 0.1325951 Vali Loss: 0.1116240 Test Loss: 0.1327385\n",
            "Validation loss decreased (0.111943 --> 0.111624).  Saving model ...\n",
            "Updating learning rate to 7.8125e-07\n",
            "\titers: 100, epoch: 9 | loss: 0.1443239\n",
            "\tspeed: 7.8773s/iter; left time: 51115.8898s\n",
            "\titers: 200, epoch: 9 | loss: 0.1213750\n",
            "\tspeed: 8.0078s/iter; left time: 51161.8007s\n",
            "\titers: 300, epoch: 9 | loss: 0.1275910\n",
            "\tspeed: 8.1381s/iter; left time: 51180.2800s\n",
            "\titers: 400, epoch: 9 | loss: 0.1078884\n",
            "\tspeed: 8.2673s/iter; left time: 51166.5807s\n",
            "\titers: 500, epoch: 9 | loss: 0.1278367\n",
            "\tspeed: 8.3942s/iter; left time: 51112.5032s\n",
            "Epoch: 9 cost time: 71.692134141922\n",
            "Epoch: 9, Steps: 549 | Train Loss: 0.1325597 Vali Loss: 0.1115807 Test Loss: 0.1327726\n",
            "Validation loss decreased (0.111624 --> 0.111581).  Saving model ...\n",
            "Updating learning rate to 3.90625e-07\n",
            "\titers: 100, epoch: 10 | loss: 0.1172276\n",
            "\tspeed: 8.8401s/iter; left time: 52510.1175s\n",
            "\titers: 200, epoch: 10 | loss: 0.1329177\n",
            "\tspeed: 8.9699s/iter; left time: 52383.9504s\n",
            "\titers: 300, epoch: 10 | loss: 0.1312844\n",
            "\tspeed: 9.0999s/iter; left time: 52233.5932s\n",
            "\titers: 400, epoch: 10 | loss: 0.1365199\n",
            "\tspeed: 9.2292s/iter; left time: 52052.8826s\n",
            "\titers: 500, epoch: 10 | loss: 0.1210036\n",
            "\tspeed: 9.3567s/iter; left time: 51836.3737s\n",
            "Epoch: 10 cost time: 71.59771943092346\n",
            "Epoch: 10, Steps: 549 | Train Loss: 0.1324661 Vali Loss: 0.1113388 Test Loss: 0.1328568\n",
            "Validation loss decreased (0.111581 --> 0.111339).  Saving model ...\n",
            "Updating learning rate to 1.953125e-07\n",
            "\titers: 100, epoch: 11 | loss: 0.1401012\n",
            "\tspeed: 9.8019s/iter; left time: 52842.2870s\n",
            "\titers: 200, epoch: 11 | loss: 0.1316091\n",
            "\tspeed: 9.9301s/iter; left time: 52540.3532s\n",
            "\titers: 300, epoch: 11 | loss: 0.1314421\n",
            "\tspeed: 10.0593s/iter; left time: 52217.8190s\n",
            "\titers: 400, epoch: 11 | loss: 0.1286679\n",
            "\tspeed: 10.1873s/iter; left time: 51863.7867s\n",
            "\titers: 500, epoch: 11 | loss: 0.1257747\n",
            "\tspeed: 10.3145s/iter; left time: 51479.8331s\n",
            "Epoch: 11 cost time: 71.15554475784302\n",
            "Epoch: 11, Steps: 549 | Train Loss: 0.1324387 Vali Loss: 0.1114239 Test Loss: 0.1326995\n",
            "EarlyStopping counter: 1 out of 3\n",
            "Updating learning rate to 9.765625e-08\n",
            "\titers: 100, epoch: 12 | loss: 0.1242295\n",
            "\tspeed: 10.7601s/iter; left time: 52100.3226s\n",
            "\titers: 200, epoch: 12 | loss: 0.1152589\n",
            "\tspeed: 10.8898s/iter; left time: 51639.4453s\n",
            "\titers: 300, epoch: 12 | loss: 0.1306213\n",
            "\tspeed: 11.0198s/iter; left time: 51153.9280s\n",
            "\titers: 400, epoch: 12 | loss: 0.1409974\n",
            "\tspeed: 11.1491s/iter; left time: 50639.3008s\n",
            "\titers: 500, epoch: 12 | loss: 0.1643938\n",
            "\tspeed: 11.2762s/iter; left time: 50088.8048s\n",
            "Epoch: 12 cost time: 71.60159802436829\n",
            "Epoch: 12, Steps: 549 | Train Loss: 0.1324208 Vali Loss: 0.1115087 Test Loss: 0.1325918\n",
            "EarlyStopping counter: 2 out of 3\n",
            "Updating learning rate to 4.8828125e-08\n",
            "\titers: 100, epoch: 13 | loss: 0.1209855\n",
            "\tspeed: 11.7199s/iter; left time: 50313.6679s\n",
            "\titers: 200, epoch: 13 | loss: 0.1224768\n",
            "\tspeed: 11.8491s/iter; left time: 49683.4746s\n",
            "\titers: 300, epoch: 13 | loss: 0.1173802\n",
            "\tspeed: 11.9790s/iter; left time: 49030.1620s\n",
            "\titers: 400, epoch: 13 | loss: 0.1463694\n",
            "\tspeed: 12.1083s/iter; left time: 48348.4332s\n",
            "\titers: 500, epoch: 13 | loss: 0.1269199\n",
            "\tspeed: 12.2356s/iter; left time: 47633.2703s\n",
            "Epoch: 13 cost time: 71.48923182487488\n",
            "Epoch: 13, Steps: 549 | Train Loss: 0.1324346 Vali Loss: 0.1114438 Test Loss: 0.1326259\n",
            "EarlyStopping counter: 3 out of 3\n",
            "Early stopping\n",
            ">>>>>>>testing : Linear_PatchTST_Model-6_ECL_ftM_sl720_ll48_pl96_dm512_nh8_el2_dl1_df2048_atprob_fc3_ebtimeF_dtTrue_mxNone_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 5165\n",
            "mse:0.13285663723945618, mae:0.22982653975486755, rse:0.3623640537261963\n",
            "Length of train/test for pred length {} : {} sec or {} mins  96 1283.1477720737457 21.385796201229095\n",
            "Linear_PatchTST_Model-6_ECL_ftM_sl720_ll48_pl192_dm512_nh8_el2_dl1_df2048_atprob_fc3_ebtimeF_dtTrue_mxNone_Exp_0\n",
            "Linear_PatchTST_Model-6_ECL_ftM_sl720_ll48_pl192_dm512_nh8_el2_dl1_df2048_atprob_fc3_ebtimeF_dtTrue_mxNone_Exp_0\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : Linear_PatchTST_Model-6_ECL_ftM_sl720_ll48_pl192_dm512_nh8_el2_dl1_df2048_atprob_fc3_ebtimeF_dtTrue_mxNone_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 17501\n",
            "val 2441\n",
            "test 5069\n",
            "\titers: 100, epoch: 1 | loss: 0.2239633\n",
            "\tspeed: 0.2252s/iter; left time: 2437.3140s\n",
            "\titers: 200, epoch: 1 | loss: 0.1810314\n",
            "\tspeed: 0.3934s/iter; left time: 4217.1349s\n",
            "\titers: 300, epoch: 1 | loss: 0.1732673\n",
            "\tspeed: 0.5589s/iter; left time: 5936.1052s\n",
            "\titers: 400, epoch: 1 | loss: 0.1738243\n",
            "\tspeed: 0.7228s/iter; left time: 7604.9100s\n",
            "\titers: 500, epoch: 1 | loss: 0.1994219\n",
            "\tspeed: 0.8866s/iter; left time: 9239.3720s\n",
            "Epoch: 1 cost time: 92.05619406700134\n",
            "Epoch: 1, Steps: 546 | Train Loss: 0.2144809 Vali Loss: 0.1394880 Test Loss: 0.1639663\n",
            "Validation loss decreased (inf --> 0.139488).  Saving model ...\n",
            "Updating learning rate to 0.0001\n",
            "\titers: 100, epoch: 2 | loss: 0.1803522\n",
            "\tspeed: 1.4319s/iter; left time: 14712.3563s\n",
            "\titers: 200, epoch: 2 | loss: 0.1466050\n",
            "\tspeed: 1.5984s/iter; left time: 16263.9825s\n",
            "\titers: 300, epoch: 2 | loss: 0.1751345\n",
            "\tspeed: 1.7639s/iter; left time: 17770.8122s\n",
            "\titers: 400, epoch: 2 | loss: 0.1639673\n",
            "\tspeed: 1.9283s/iter; left time: 19234.9343s\n",
            "\titers: 500, epoch: 2 | loss: 0.1573618\n",
            "\tspeed: 2.0927s/iter; left time: 20665.8632s\n",
            "Epoch: 2 cost time: 91.6760184764862\n",
            "Epoch: 2, Steps: 546 | Train Loss: 0.1632575 Vali Loss: 0.1312038 Test Loss: 0.1542767\n",
            "Validation loss decreased (0.139488 --> 0.131204).  Saving model ...\n",
            "Updating learning rate to 5e-05\n",
            "\titers: 100, epoch: 3 | loss: 0.1434564\n",
            "\tspeed: 2.6385s/iter; left time: 25670.0379s\n",
            "\titers: 200, epoch: 3 | loss: 0.1712283\n",
            "\tspeed: 2.8049s/iter; left time: 27008.3275s\n",
            "\titers: 300, epoch: 3 | loss: 0.1522966\n",
            "\tspeed: 2.9705s/iter; left time: 28305.6431s\n",
            "\titers: 400, epoch: 3 | loss: 0.1384636\n",
            "\tspeed: 3.1351s/iter; left time: 29560.8275s\n",
            "\titers: 500, epoch: 3 | loss: 0.1406936\n",
            "\tspeed: 3.2996s/iter; left time: 30782.2526s\n",
            "Epoch: 3 cost time: 91.67976260185242\n",
            "Epoch: 3, Steps: 546 | Train Loss: 0.1523216 Vali Loss: 0.1310068 Test Loss: 0.1521948\n",
            "Validation loss decreased (0.131204 --> 0.131007).  Saving model ...\n",
            "Updating learning rate to 2.5e-05\n",
            "\titers: 100, epoch: 4 | loss: 0.1790910\n",
            "\tspeed: 3.8441s/iter; left time: 35300.3942s\n",
            "\titers: 200, epoch: 4 | loss: 0.1340083\n",
            "\tspeed: 4.0106s/iter; left time: 36428.4292s\n",
            "\titers: 300, epoch: 4 | loss: 0.1437567\n",
            "\tspeed: 4.1763s/iter; left time: 37515.3308s\n",
            "\titers: 400, epoch: 4 | loss: 0.1535477\n",
            "\tspeed: 4.3409s/iter; left time: 38560.4095s\n",
            "\titers: 500, epoch: 4 | loss: 0.1659662\n",
            "\tspeed: 4.5053s/iter; left time: 39570.3335s\n",
            "Epoch: 4 cost time: 91.71807360649109\n",
            "Epoch: 4, Steps: 546 | Train Loss: 0.1497239 Vali Loss: 0.1249714 Test Loss: 0.1485601\n",
            "Validation loss decreased (0.131007 --> 0.124971).  Saving model ...\n",
            "Updating learning rate to 1.25e-05\n",
            "\titers: 100, epoch: 5 | loss: 0.1599415\n",
            "\tspeed: 5.0519s/iter; left time: 43633.2276s\n",
            "\titers: 200, epoch: 5 | loss: 0.1479044\n",
            "\tspeed: 5.2188s/iter; left time: 44553.2033s\n",
            "\titers: 300, epoch: 5 | loss: 0.1520396\n",
            "\tspeed: 5.3844s/iter; left time: 45428.5923s\n",
            "\titers: 400, epoch: 5 | loss: 0.1590870\n",
            "\tspeed: 5.5489s/iter; left time: 46261.4619s\n",
            "\titers: 500, epoch: 5 | loss: 0.1476659\n",
            "\tspeed: 5.7132s/iter; left time: 47059.6286s\n",
            "Epoch: 5 cost time: 91.72892999649048\n",
            "Epoch: 5, Steps: 546 | Train Loss: 0.1485840 Vali Loss: 0.1264325 Test Loss: 0.1485253\n",
            "EarlyStopping counter: 1 out of 3\n",
            "Updating learning rate to 6.25e-06\n",
            "\titers: 100, epoch: 6 | loss: 0.1607793\n",
            "\tspeed: 6.2608s/iter; left time: 50655.7921s\n",
            "\titers: 200, epoch: 6 | loss: 0.1552304\n",
            "\tspeed: 6.4279s/iter; left time: 51365.0855s\n",
            "\titers: 300, epoch: 6 | loss: 0.1399967\n",
            "\tspeed: 6.5933s/iter; left time: 52027.9042s\n",
            "\titers: 400, epoch: 6 | loss: 0.1648736\n",
            "\tspeed: 6.7577s/iter; left time: 52649.5729s\n",
            "\titers: 500, epoch: 6 | loss: 0.1529028\n",
            "\tspeed: 6.9219s/iter; left time: 53236.1343s\n",
            "Epoch: 6 cost time: 91.7590434551239\n",
            "Epoch: 6, Steps: 546 | Train Loss: 0.1478215 Vali Loss: 0.1232755 Test Loss: 0.1469379\n",
            "Validation loss decreased (0.124971 --> 0.123275).  Saving model ...\n",
            "Updating learning rate to 3.125e-06\n",
            "\titers: 100, epoch: 7 | loss: 0.1400930\n",
            "\tspeed: 7.4674s/iter; left time: 56341.8540s\n",
            "\titers: 200, epoch: 7 | loss: 0.1396818\n",
            "\tspeed: 7.6340s/iter; left time: 56835.1857s\n",
            "\titers: 300, epoch: 7 | loss: 0.1381726\n",
            "\tspeed: 7.7994s/iter; left time: 57286.7128s\n",
            "\titers: 400, epoch: 7 | loss: 0.1402602\n",
            "\tspeed: 7.9640s/iter; left time: 57698.9097s\n",
            "\titers: 500, epoch: 7 | loss: 0.1514170\n",
            "\tspeed: 8.1283s/iter; left time: 58076.5145s\n",
            "Epoch: 7 cost time: 91.68407893180847\n",
            "Epoch: 7, Steps: 546 | Train Loss: 0.1474506 Vali Loss: 0.1230827 Test Loss: 0.1469697\n",
            "Validation loss decreased (0.123275 --> 0.123083).  Saving model ...\n",
            "Updating learning rate to 1.5625e-06\n",
            "\titers: 100, epoch: 8 | loss: 0.1366317\n",
            "\tspeed: 8.6763s/iter; left time: 60725.3004s\n",
            "\titers: 200, epoch: 8 | loss: 0.1541589\n",
            "\tspeed: 8.8429s/iter; left time: 61007.2597s\n",
            "\titers: 300, epoch: 8 | loss: 0.1454001\n",
            "\tspeed: 9.0082s/iter; left time: 61246.8110s\n",
            "\titers: 400, epoch: 8 | loss: 0.1593663\n",
            "\tspeed: 9.1724s/iter; left time: 61445.9962s\n",
            "\titers: 500, epoch: 8 | loss: 0.1596430\n",
            "\tspeed: 9.3367s/iter; left time: 61612.9628s\n",
            "Epoch: 8 cost time: 91.69079065322876\n",
            "Epoch: 8, Steps: 546 | Train Loss: 0.1472278 Vali Loss: 0.1232139 Test Loss: 0.1465891\n",
            "EarlyStopping counter: 1 out of 3\n",
            "Updating learning rate to 7.8125e-07\n",
            "\titers: 100, epoch: 9 | loss: 0.1416858\n",
            "\tspeed: 9.8845s/iter; left time: 63784.7798s\n",
            "\titers: 200, epoch: 9 | loss: 0.1539894\n",
            "\tspeed: 10.0516s/iter; left time: 63857.9556s\n",
            "\titers: 300, epoch: 9 | loss: 0.1462877\n",
            "\tspeed: 10.2172s/iter; left time: 63888.3751s\n",
            "\titers: 400, epoch: 9 | loss: 0.1523804\n",
            "\tspeed: 10.3818s/iter; left time: 63879.2414s\n",
            "\titers: 500, epoch: 9 | loss: 0.1414782\n",
            "\tspeed: 10.5462s/iter; left time: 63836.3034s\n",
            "Epoch: 9 cost time: 91.79521083831787\n",
            "Epoch: 9, Steps: 546 | Train Loss: 0.1470669 Vali Loss: 0.1233033 Test Loss: 0.1465366\n",
            "EarlyStopping counter: 2 out of 3\n",
            "Updating learning rate to 3.90625e-07\n",
            "\titers: 100, epoch: 10 | loss: 0.1209678\n",
            "\tspeed: 11.0952s/iter; left time: 65539.3657s\n",
            "\titers: 200, epoch: 10 | loss: 0.1386471\n",
            "\tspeed: 11.2625s/iter; left time: 65401.6046s\n",
            "\titers: 300, epoch: 10 | loss: 0.1520738\n",
            "\tspeed: 11.4287s/iter; left time: 65223.4711s\n",
            "\titers: 400, epoch: 10 | loss: 0.1590745\n",
            "\tspeed: 11.5933s/iter; left time: 65003.5356s\n",
            "\titers: 500, epoch: 10 | loss: 0.1630619\n",
            "\tspeed: 11.7578s/iter; left time: 64750.3601s\n",
            "Epoch: 10 cost time: 91.97618746757507\n",
            "Epoch: 10, Steps: 546 | Train Loss: 0.1470214 Vali Loss: 0.1229759 Test Loss: 0.1464756\n",
            "Validation loss decreased (0.123083 --> 0.122976).  Saving model ...\n",
            "Updating learning rate to 1.953125e-07\n",
            "\titers: 100, epoch: 11 | loss: 0.1563284\n",
            "\tspeed: 12.3083s/iter; left time: 65984.5584s\n",
            "\titers: 200, epoch: 11 | loss: 0.1489585\n",
            "\tspeed: 12.4752s/iter; left time: 65631.9544s\n",
            "\titers: 300, epoch: 11 | loss: 0.1429745\n",
            "\tspeed: 12.6408s/iter; left time: 65238.9765s\n",
            "\titers: 400, epoch: 11 | loss: 0.1505579\n",
            "\tspeed: 12.8056s/iter; left time: 64809.2104s\n",
            "\titers: 500, epoch: 11 | loss: 0.1462556\n",
            "\tspeed: 12.9703s/iter; left time: 64345.4595s\n",
            "Epoch: 11 cost time: 91.91371440887451\n",
            "Epoch: 11, Steps: 546 | Train Loss: 0.1469463 Vali Loss: 0.1230851 Test Loss: 0.1465124\n",
            "EarlyStopping counter: 1 out of 3\n",
            "Updating learning rate to 9.765625e-08\n",
            "\titers: 100, epoch: 12 | loss: 0.1302703\n",
            "\tspeed: 13.5159s/iter; left time: 65078.9246s\n",
            "\titers: 200, epoch: 12 | loss: 0.1568364\n",
            "\tspeed: 13.6813s/iter; left time: 64507.5508s\n",
            "\titers: 300, epoch: 12 | loss: 0.1647860\n",
            "\tspeed: 13.8457s/iter; left time: 63897.8253s\n",
            "\titers: 400, epoch: 12 | loss: 0.1477314\n",
            "\tspeed: 14.0100s/iter; left time: 63255.2823s\n",
            "\titers: 500, epoch: 12 | loss: 0.1314011\n",
            "\tspeed: 14.1748s/iter; left time: 62581.7926s\n",
            "Epoch: 12 cost time: 91.47512078285217\n",
            "Epoch: 12, Steps: 546 | Train Loss: 0.1469481 Vali Loss: 0.1228580 Test Loss: 0.1463295\n",
            "Validation loss decreased (0.122976 --> 0.122858).  Saving model ...\n",
            "Updating learning rate to 4.8828125e-08\n",
            "\titers: 100, epoch: 13 | loss: 0.1777772\n",
            "\tspeed: 14.7233s/iter; left time: 62853.8774s\n",
            "\titers: 200, epoch: 13 | loss: 0.1486769\n",
            "\tspeed: 14.8886s/iter; left time: 62070.5549s\n",
            "\titers: 300, epoch: 13 | loss: 0.1579734\n",
            "\tspeed: 15.0529s/iter; left time: 61250.3028s\n",
            "\titers: 400, epoch: 13 | loss: 0.1502844\n",
            "\tspeed: 15.2169s/iter; left time: 60395.7276s\n",
            "\titers: 500, epoch: 13 | loss: 0.1587082\n",
            "\tspeed: 15.3817s/iter; left time: 59511.7848s\n",
            "Epoch: 13 cost time: 91.40010929107666\n",
            "Epoch: 13, Steps: 546 | Train Loss: 0.1469528 Vali Loss: 0.1228675 Test Loss: 0.1463633\n",
            "EarlyStopping counter: 1 out of 3\n",
            "Updating learning rate to 2.44140625e-08\n",
            "\titers: 100, epoch: 14 | loss: 0.1514791\n",
            "\tspeed: 15.9313s/iter; left time: 59312.3658s\n",
            "\titers: 200, epoch: 14 | loss: 0.1508999\n",
            "\tspeed: 16.0968s/iter; left time: 58318.6074s\n",
            "\titers: 300, epoch: 14 | loss: 0.1404776\n",
            "\tspeed: 16.2611s/iter; left time: 57287.9958s\n",
            "\titers: 400, epoch: 14 | loss: 0.1667695\n",
            "\tspeed: 16.4255s/iter; left time: 56224.4051s\n",
            "\titers: 500, epoch: 14 | loss: 0.1583545\n",
            "\tspeed: 16.5902s/iter; left time: 55129.2482s\n",
            "Epoch: 14 cost time: 91.66604495048523\n",
            "Epoch: 14, Steps: 546 | Train Loss: 0.1469343 Vali Loss: 0.1229762 Test Loss: 0.1463598\n",
            "EarlyStopping counter: 2 out of 3\n",
            "Updating learning rate to 1.220703125e-08\n",
            "\titers: 100, epoch: 15 | loss: 0.1390783\n",
            "\tspeed: 17.1383s/iter; left time: 54448.2478s\n",
            "\titers: 200, epoch: 15 | loss: 0.1365947\n",
            "\tspeed: 17.3038s/iter; left time: 53243.6924s\n",
            "\titers: 300, epoch: 15 | loss: 0.1539198\n",
            "\tspeed: 17.4681s/iter; left time: 52002.5126s\n",
            "\titers: 400, epoch: 15 | loss: 0.1435531\n",
            "\tspeed: 17.6325s/iter; left time: 50728.5871s\n",
            "\titers: 500, epoch: 15 | loss: 0.1398042\n",
            "\tspeed: 17.7972s/iter; left time: 49422.8716s\n",
            "Epoch: 15 cost time: 91.50462651252747\n",
            "Epoch: 15, Steps: 546 | Train Loss: 0.1469432 Vali Loss: 0.1229187 Test Loss: 0.1463604\n",
            "EarlyStopping counter: 3 out of 3\n",
            "Early stopping\n",
            ">>>>>>>testing : Linear_PatchTST_Model-6_ECL_ftM_sl720_ll48_pl192_dm512_nh8_el2_dl1_df2048_atprob_fc3_ebtimeF_dtTrue_mxNone_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 5069\n",
            "mse:0.14632925391197205, mae:0.2431633323431015, rse:0.3805011808872223\n",
            "Length of train/test for pred length {} : {} sec or {} mins  192 1854.9521071910858 30.915868453184764\n",
            "Linear_PatchTST_Model-6_ECL_ftM_sl720_ll48_pl336_dm512_nh8_el2_dl1_df2048_atprob_fc3_ebtimeF_dtTrue_mxNone_Exp_0\n",
            "Linear_PatchTST_Model-6_ECL_ftM_sl720_ll48_pl336_dm512_nh8_el2_dl1_df2048_atprob_fc3_ebtimeF_dtTrue_mxNone_Exp_0\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : Linear_PatchTST_Model-6_ECL_ftM_sl720_ll48_pl336_dm512_nh8_el2_dl1_df2048_atprob_fc3_ebtimeF_dtTrue_mxNone_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 17357\n",
            "val 2297\n",
            "test 4925\n",
            "\titers: 100, epoch: 1 | loss: 0.2270666\n",
            "\tspeed: 0.2565s/iter; left time: 2755.2912s\n",
            "\titers: 200, epoch: 1 | loss: 0.2017378\n",
            "\tspeed: 0.4569s/iter; left time: 4861.5868s\n",
            "\titers: 300, epoch: 1 | loss: 0.1918617\n",
            "\tspeed: 0.6552s/iter; left time: 6906.7609s\n",
            "\titers: 400, epoch: 1 | loss: 0.1850589\n",
            "\tspeed: 0.8532s/iter; left time: 8908.1394s\n",
            "\titers: 500, epoch: 1 | loss: 0.1762224\n",
            "\tspeed: 1.0513s/iter; left time: 10871.5820s\n",
            "Epoch: 1 cost time: 109.40962839126587\n",
            "Epoch: 1, Steps: 542 | Train Loss: 0.2322760 Vali Loss: 0.1531297 Test Loss: 0.1782769\n",
            "Validation loss decreased (inf --> 0.153130).  Saving model ...\n",
            "Updating learning rate to 0.0001\n",
            "\titers: 100, epoch: 2 | loss: 0.2174339\n",
            "\tspeed: 1.6921s/iter; left time: 17257.3624s\n",
            "\titers: 200, epoch: 2 | loss: 0.2018274\n",
            "\tspeed: 1.8904s/iter; left time: 19091.2146s\n",
            "\titers: 300, epoch: 2 | loss: 0.1785818\n",
            "\tspeed: 2.0890s/iter; left time: 20887.9869s\n",
            "\titers: 400, epoch: 2 | loss: 0.1698779\n",
            "\tspeed: 2.2872s/iter; left time: 22641.3678s\n",
            "\titers: 500, epoch: 2 | loss: 0.1765245\n",
            "\tspeed: 2.4861s/iter; left time: 24360.8671s\n",
            "Epoch: 2 cost time: 109.14136266708374\n",
            "Epoch: 2, Steps: 542 | Train Loss: 0.1844127 Vali Loss: 0.1485883 Test Loss: 0.1714757\n",
            "Validation loss decreased (0.153130 --> 0.148588).  Saving model ...\n",
            "Updating learning rate to 5e-05\n",
            "\titers: 100, epoch: 3 | loss: 0.1779582\n",
            "\tspeed: 3.1287s/iter; left time: 30213.7677s\n",
            "\titers: 200, epoch: 3 | loss: 0.1734222\n",
            "\tspeed: 3.3286s/iter; left time: 31811.3945s\n",
            "\titers: 300, epoch: 3 | loss: 0.1820631\n",
            "\tspeed: 3.5274s/iter; left time: 33359.0327s\n",
            "\titers: 400, epoch: 3 | loss: 0.1865311\n",
            "\tspeed: 3.7259s/iter; left time: 34863.4748s\n",
            "\titers: 500, epoch: 3 | loss: 0.1765974\n",
            "\tspeed: 3.9249s/iter; left time: 36333.2179s\n",
            "Epoch: 3 cost time: 109.51337003707886\n",
            "Epoch: 3, Steps: 542 | Train Loss: 0.1729665 Vali Loss: 0.1421013 Test Loss: 0.1650944\n",
            "Validation loss decreased (0.148588 --> 0.142101).  Saving model ...\n",
            "Updating learning rate to 2.5e-05\n",
            "\titers: 100, epoch: 4 | loss: 0.1419164\n",
            "\tspeed: 4.5692s/iter; left time: 41647.9427s\n",
            "\titers: 200, epoch: 4 | loss: 0.1722847\n",
            "\tspeed: 4.7676s/iter; left time: 42980.0023s\n",
            "\titers: 300, epoch: 4 | loss: 0.1689349\n",
            "\tspeed: 4.9659s/iter; left time: 44271.3037s\n",
            "\titers: 400, epoch: 4 | loss: 0.2172449\n",
            "\tspeed: 5.1641s/iter; left time: 45521.4229s\n",
            "\titers: 500, epoch: 4 | loss: 0.1961236\n",
            "\tspeed: 5.3629s/iter; left time: 46737.3691s\n",
            "Epoch: 4 cost time: 109.16421794891357\n",
            "Epoch: 4, Steps: 542 | Train Loss: 0.1701256 Vali Loss: 0.1397202 Test Loss: 0.1622299\n",
            "Validation loss decreased (0.142101 --> 0.139720).  Saving model ...\n",
            "Updating learning rate to 1.25e-05\n",
            "\titers: 100, epoch: 5 | loss: 0.1578637\n",
            "\tspeed: 6.0074s/iter; left time: 51501.7749s\n",
            "\titers: 200, epoch: 5 | loss: 0.1585281\n",
            "\tspeed: 6.2057s/iter; left time: 52580.6157s\n",
            "\titers: 300, epoch: 5 | loss: 0.1445547\n",
            "\tspeed: 6.4038s/iter; left time: 53619.3945s\n",
            "\titers: 400, epoch: 5 | loss: 0.1622891\n",
            "\tspeed: 6.6021s/iter; left time: 54619.0603s\n",
            "\titers: 500, epoch: 5 | loss: 0.1457171\n",
            "\tspeed: 6.8010s/iter; left time: 55584.4824s\n",
            "Epoch: 5 cost time: 109.181889295578\n",
            "Epoch: 5, Steps: 542 | Train Loss: 0.1688019 Vali Loss: 0.1391260 Test Loss: 0.1632733\n",
            "Validation loss decreased (0.139720 --> 0.139126).  Saving model ...\n",
            "Updating learning rate to 6.25e-06\n",
            "\titers: 100, epoch: 6 | loss: 0.1496549\n",
            "\tspeed: 7.4410s/iter; left time: 59758.9670s\n",
            "\titers: 200, epoch: 6 | loss: 0.1786929\n",
            "\tspeed: 7.6394s/iter; left time: 60588.1027s\n",
            "\titers: 300, epoch: 6 | loss: 0.1572594\n",
            "\tspeed: 7.8374s/iter; left time: 61375.0189s\n",
            "\titers: 400, epoch: 6 | loss: 0.1785893\n",
            "\tspeed: 8.0357s/iter; left time: 62123.9858s\n",
            "\titers: 500, epoch: 6 | loss: 0.1699721\n",
            "\tspeed: 8.2345s/iter; left time: 62837.8056s\n",
            "Epoch: 6 cost time: 109.1064682006836\n",
            "Epoch: 6, Steps: 542 | Train Loss: 0.1681602 Vali Loss: 0.1392323 Test Loss: 0.1625623\n",
            "EarlyStopping counter: 1 out of 3\n",
            "Updating learning rate to 3.125e-06\n",
            "\titers: 100, epoch: 7 | loss: 0.1643444\n",
            "\tspeed: 8.8734s/iter; left time: 66453.2161s\n",
            "\titers: 200, epoch: 7 | loss: 0.1648378\n",
            "\tspeed: 9.0719s/iter; left time: 67032.0708s\n",
            "\titers: 300, epoch: 7 | loss: 0.1650824\n",
            "\tspeed: 9.2703s/iter; left time: 67571.2422s\n",
            "\titers: 400, epoch: 7 | loss: 0.1583114\n",
            "\tspeed: 9.4687s/iter; left time: 68070.2891s\n",
            "\titers: 500, epoch: 7 | loss: 0.1656068\n",
            "\tspeed: 9.6676s/iter; left time: 68533.4389s\n",
            "Epoch: 7 cost time: 109.25495529174805\n",
            "Epoch: 7, Steps: 542 | Train Loss: 0.1677471 Vali Loss: 0.1372098 Test Loss: 0.1612946\n",
            "Validation loss decreased (0.139126 --> 0.137210).  Saving model ...\n",
            "Updating learning rate to 1.5625e-06\n",
            "\titers: 100, epoch: 8 | loss: 0.1977776\n",
            "\tspeed: 10.3128s/iter; left time: 71643.0414s\n",
            "\titers: 200, epoch: 8 | loss: 0.1621684\n",
            "\tspeed: 10.5127s/iter; left time: 71980.2449s\n",
            "\titers: 300, epoch: 8 | loss: 0.1981340\n",
            "\tspeed: 10.7115s/iter; left time: 72270.7002s\n",
            "\titers: 400, epoch: 8 | loss: 0.1741846\n",
            "\tspeed: 10.9099s/iter; left time: 72518.3985s\n",
            "\titers: 500, epoch: 8 | loss: 0.1714084\n",
            "\tspeed: 11.1088s/iter; left time: 72729.4961s\n",
            "Epoch: 8 cost time: 109.47916173934937\n",
            "Epoch: 8, Steps: 542 | Train Loss: 0.1674411 Vali Loss: 0.1370561 Test Loss: 0.1617809\n",
            "Validation loss decreased (0.137210 --> 0.137056).  Saving model ...\n",
            "Updating learning rate to 7.8125e-07\n",
            "\titers: 100, epoch: 9 | loss: 0.1672040\n",
            "\tspeed: 11.7494s/iter; left time: 75254.6214s\n",
            "\titers: 200, epoch: 9 | loss: 0.2019789\n",
            "\tspeed: 11.9479s/iter; left time: 75331.3575s\n",
            "\titers: 300, epoch: 9 | loss: 0.1776168\n",
            "\tspeed: 12.1463s/iter; left time: 75367.5188s\n",
            "\titers: 400, epoch: 9 | loss: 0.1744505\n",
            "\tspeed: 12.3445s/iter; left time: 75363.2241s\n",
            "\titers: 500, epoch: 9 | loss: 0.1550646\n",
            "\tspeed: 12.5432s/iter; left time: 75321.6420s\n",
            "Epoch: 9 cost time: 109.14696741104126\n",
            "Epoch: 9, Steps: 542 | Train Loss: 0.1672895 Vali Loss: 0.1366847 Test Loss: 0.1613827\n",
            "Validation loss decreased (0.137056 --> 0.136685).  Saving model ...\n",
            "Updating learning rate to 3.90625e-07\n",
            "\titers: 100, epoch: 10 | loss: 0.1801654\n",
            "\tspeed: 13.1844s/iter; left time: 77299.8784s\n",
            "\titers: 200, epoch: 10 | loss: 0.1864337\n",
            "\tspeed: 13.3825s/iter; left time: 77123.5575s\n",
            "\titers: 300, epoch: 10 | loss: 0.1678814\n",
            "\tspeed: 13.5810s/iter; left time: 76909.4246s\n",
            "\titers: 400, epoch: 10 | loss: 0.1669053\n",
            "\tspeed: 13.7794s/iter; left time: 76654.9952s\n",
            "\titers: 500, epoch: 10 | loss: 0.1591957\n",
            "\tspeed: 13.9783s/iter; left time: 76363.4177s\n",
            "Epoch: 10 cost time: 109.28022861480713\n",
            "Epoch: 10, Steps: 542 | Train Loss: 0.1672436 Vali Loss: 0.1371391 Test Loss: 0.1611113\n",
            "EarlyStopping counter: 1 out of 3\n",
            "Updating learning rate to 1.953125e-07\n",
            "\titers: 100, epoch: 11 | loss: 0.1855457\n",
            "\tspeed: 14.6224s/iter; left time: 77805.9844s\n",
            "\titers: 200, epoch: 11 | loss: 0.1581622\n",
            "\tspeed: 14.8207s/iter; left time: 77379.0199s\n",
            "\titers: 300, epoch: 11 | loss: 0.1798447\n",
            "\tspeed: 15.0194s/iter; left time: 76914.1755s\n",
            "\titers: 400, epoch: 11 | loss: 0.1596744\n",
            "\tspeed: 15.2180s/iter; left time: 76409.3944s\n",
            "\titers: 500, epoch: 11 | loss: 0.1808482\n",
            "\tspeed: 15.4169s/iter; left time: 75866.3247s\n",
            "Epoch: 11 cost time: 109.23401522636414\n",
            "Epoch: 11, Steps: 542 | Train Loss: 0.1671941 Vali Loss: 0.1369318 Test Loss: 0.1611998\n",
            "EarlyStopping counter: 2 out of 3\n",
            "Updating learning rate to 9.765625e-08\n",
            "\titers: 100, epoch: 12 | loss: 0.1495494\n",
            "\tspeed: 16.0560s/iter; left time: 76731.6021s\n",
            "\titers: 200, epoch: 12 | loss: 0.1797940\n",
            "\tspeed: 16.2543s/iter; left time: 76054.0621s\n",
            "\titers: 300, epoch: 12 | loss: 0.1628623\n",
            "\tspeed: 16.4529s/iter; left time: 75337.6987s\n",
            "\titers: 400, epoch: 12 | loss: 0.1589952\n",
            "\tspeed: 16.6511s/iter; left time: 74580.4201s\n",
            "\titers: 500, epoch: 12 | loss: 0.1550179\n",
            "\tspeed: 16.8499s/iter; left time: 73785.7672s\n",
            "Epoch: 12 cost time: 109.20202279090881\n",
            "Epoch: 12, Steps: 542 | Train Loss: 0.1671513 Vali Loss: 0.1370214 Test Loss: 0.1612415\n",
            "EarlyStopping counter: 3 out of 3\n",
            "Early stopping\n",
            ">>>>>>>testing : Linear_PatchTST_Model-6_ECL_ftM_sl720_ll48_pl336_dm512_nh8_el2_dl1_df2048_atprob_fc3_ebtimeF_dtTrue_mxNone_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 4925\n",
            "mse:0.16138234734535217, mae:0.26026374101638794, rse:0.4001316726207733\n",
            "Length of train/test for pred length {} : {} sec or {} mins  336 1775.6340568065643 29.59390094677607\n",
            "Linear_PatchTST_Model-6_ECL_ftM_sl720_ll48_pl720_dm512_nh8_el2_dl1_df2048_atprob_fc3_ebtimeF_dtTrue_mxNone_Exp_0\n",
            "Linear_PatchTST_Model-6_ECL_ftM_sl720_ll48_pl720_dm512_nh8_el2_dl1_df2048_atprob_fc3_ebtimeF_dtTrue_mxNone_Exp_0\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : Linear_PatchTST_Model-6_ECL_ftM_sl720_ll48_pl720_dm512_nh8_el2_dl1_df2048_atprob_fc3_ebtimeF_dtTrue_mxNone_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 16973\n",
            "val 1913\n",
            "test 4541\n",
            "\titers: 100, epoch: 1 | loss: 0.2846715\n",
            "\tspeed: 0.3671s/iter; left time: 3854.8855s\n",
            "\titers: 200, epoch: 1 | loss: 0.2417873\n",
            "\tspeed: 0.6703s/iter; left time: 6971.9714s\n",
            "\titers: 300, epoch: 1 | loss: 0.2158963\n",
            "\tspeed: 0.9712s/iter; left time: 10004.7765s\n",
            "\titers: 400, epoch: 1 | loss: 0.2234731\n",
            "\tspeed: 1.2745s/iter; left time: 13001.5567s\n",
            "\titers: 500, epoch: 1 | loss: 0.2309657\n",
            "\tspeed: 1.5784s/iter; left time: 15943.7690s\n",
            "Epoch: 1 cost time: 162.71790766716003\n",
            "Epoch: 1, Steps: 530 | Train Loss: 0.2671661 Vali Loss: 0.1838983 Test Loss: 0.2141950\n",
            "Validation loss decreased (inf --> 0.183898).  Saving model ...\n",
            "Updating learning rate to 0.0001\n",
            "\titers: 100, epoch: 2 | loss: 0.2123828\n",
            "\tspeed: 2.4370s/iter; left time: 24299.1266s\n",
            "\titers: 200, epoch: 2 | loss: 0.2109662\n",
            "\tspeed: 2.7393s/iter; left time: 27040.0067s\n",
            "\titers: 300, epoch: 2 | loss: 0.2166335\n",
            "\tspeed: 3.0410s/iter; left time: 29713.5426s\n",
            "\titers: 400, epoch: 2 | loss: 0.2084194\n",
            "\tspeed: 3.3448s/iter; left time: 32347.5426s\n",
            "\titers: 500, epoch: 2 | loss: 0.2144856\n",
            "\tspeed: 3.6483s/iter; left time: 34918.3227s\n",
            "Epoch: 2 cost time: 162.72802925109863\n",
            "Epoch: 2, Steps: 530 | Train Loss: 0.2232675 Vali Loss: 0.1758993 Test Loss: 0.2069668\n",
            "Validation loss decreased (0.183898 --> 0.175899).  Saving model ...\n",
            "Updating learning rate to 5e-05\n",
            "\titers: 100, epoch: 3 | loss: 0.2113200\n",
            "\tspeed: 4.5328s/iter; left time: 42794.6069s\n",
            "\titers: 200, epoch: 3 | loss: 0.2324996\n",
            "\tspeed: 4.8349s/iter; left time: 45163.1451s\n",
            "\titers: 300, epoch: 3 | loss: 0.2016038\n",
            "\tspeed: 5.1360s/iter; left time: 47461.5831s\n",
            "\titers: 400, epoch: 3 | loss: 0.2363803\n",
            "\tspeed: 5.4394s/iter; left time: 49721.8306s\n",
            "\titers: 500, epoch: 3 | loss: 0.2045594\n",
            "\tspeed: 5.7432s/iter; left time: 51924.3145s\n",
            "Epoch: 3 cost time: 162.8975534439087\n",
            "Epoch: 3, Steps: 530 | Train Loss: 0.2111600 Vali Loss: 0.1725146 Test Loss: 0.2011250\n",
            "Validation loss decreased (0.175899 --> 0.172515).  Saving model ...\n",
            "Updating learning rate to 2.5e-05\n",
            "\titers: 100, epoch: 4 | loss: 0.1944993\n",
            "\tspeed: 6.6340s/iter; left time: 59115.3180s\n",
            "\titers: 200, epoch: 4 | loss: 0.2120622\n",
            "\tspeed: 6.9363s/iter; left time: 61115.3169s\n",
            "\titers: 300, epoch: 4 | loss: 0.2091873\n",
            "\tspeed: 7.2376s/iter; left time: 63046.5257s\n",
            "\titers: 400, epoch: 4 | loss: 0.2333510\n",
            "\tspeed: 7.5410s/iter; left time: 64935.6018s\n",
            "\titers: 500, epoch: 4 | loss: 0.2022905\n",
            "\tspeed: 7.8446s/iter; left time: 66765.0144s\n",
            "Epoch: 4 cost time: 162.82381296157837\n",
            "Epoch: 4, Steps: 530 | Train Loss: 0.2083427 Vali Loss: 0.1711350 Test Loss: 0.1984611\n",
            "Validation loss decreased (0.172515 --> 0.171135).  Saving model ...\n",
            "Updating learning rate to 1.25e-05\n",
            "\titers: 100, epoch: 5 | loss: 0.2098227\n",
            "\tspeed: 8.7298s/iter; left time: 73164.7837s\n",
            "\titers: 200, epoch: 5 | loss: 0.2008248\n",
            "\tspeed: 9.0318s/iter; left time: 74792.2678s\n",
            "\titers: 300, epoch: 5 | loss: 0.1992609\n",
            "\tspeed: 9.3328s/iter; left time: 76351.5942s\n",
            "\titers: 400, epoch: 5 | loss: 0.1941510\n",
            "\tspeed: 9.6363s/iter; left time: 77871.0818s\n",
            "\titers: 500, epoch: 5 | loss: 0.2347815\n",
            "\tspeed: 9.9401s/iter; left time: 79331.9404s\n",
            "Epoch: 5 cost time: 162.8924171924591\n",
            "Epoch: 5, Steps: 530 | Train Loss: 0.2066275 Vali Loss: 0.1658861 Test Loss: 0.1975517\n",
            "Validation loss decreased (0.171135 --> 0.165886).  Saving model ...\n",
            "Updating learning rate to 6.25e-06\n",
            "\titers: 100, epoch: 6 | loss: 0.1977173\n",
            "\tspeed: 10.8315s/iter; left time: 85037.7388s\n",
            "\titers: 200, epoch: 6 | loss: 0.1992673\n",
            "\tspeed: 11.1335s/iter; left time: 86296.0951s\n",
            "\titers: 300, epoch: 6 | loss: 0.1750950\n",
            "\tspeed: 11.4347s/iter; left time: 87487.1904s\n",
            "\titers: 400, epoch: 6 | loss: 0.2158861\n",
            "\tspeed: 11.7380s/iter; left time: 88634.0142s\n",
            "\titers: 500, epoch: 6 | loss: 0.2025640\n",
            "\tspeed: 12.0421s/iter; left time: 89725.4569s\n",
            "Epoch: 6 cost time: 162.85793447494507\n",
            "Epoch: 6, Steps: 530 | Train Loss: 0.2057630 Vali Loss: 0.1654536 Test Loss: 0.1964076\n",
            "Validation loss decreased (0.165886 --> 0.165454).  Saving model ...\n",
            "Updating learning rate to 3.125e-06\n",
            "\titers: 100, epoch: 7 | loss: 0.2142366\n",
            "\tspeed: 12.9270s/iter; left time: 94638.5090s\n",
            "\titers: 200, epoch: 7 | loss: 0.1974332\n",
            "\tspeed: 13.2289s/iter; left time: 95525.6724s\n",
            "\titers: 300, epoch: 7 | loss: 0.1834543\n",
            "\tspeed: 13.5297s/iter; left time: 96345.0424s\n",
            "\titers: 400, epoch: 7 | loss: 0.2458738\n",
            "\tspeed: 13.8333s/iter; left time: 97123.4363s\n",
            "\titers: 500, epoch: 7 | loss: 0.2016230\n",
            "\tspeed: 14.1371s/iter; left time: 97842.9019s\n",
            "Epoch: 7 cost time: 162.72969269752502\n",
            "Epoch: 7, Steps: 530 | Train Loss: 0.2052948 Vali Loss: 0.1655794 Test Loss: 0.1964903\n",
            "EarlyStopping counter: 1 out of 3\n",
            "Updating learning rate to 1.5625e-06\n",
            "\titers: 100, epoch: 8 | loss: 0.2253852\n",
            "\tspeed: 15.0216s/iter; left time: 102011.4305s\n",
            "\titers: 200, epoch: 8 | loss: 0.2120659\n",
            "\tspeed: 15.3240s/iter; left time: 102532.9555s\n",
            "\titers: 300, epoch: 8 | loss: 0.1997831\n",
            "\tspeed: 15.6252s/iter; left time: 102985.4712s\n",
            "\titers: 400, epoch: 8 | loss: 0.1897522\n",
            "\tspeed: 15.9283s/iter; left time: 103390.3767s\n",
            "\titers: 500, epoch: 8 | loss: 0.2219633\n",
            "\tspeed: 16.2318s/iter; left time: 103737.5499s\n",
            "Epoch: 8 cost time: 162.82454895973206\n",
            "Epoch: 8, Steps: 530 | Train Loss: 0.2049686 Vali Loss: 0.1656457 Test Loss: 0.1959623\n",
            "EarlyStopping counter: 2 out of 3\n",
            "Updating learning rate to 7.8125e-07\n",
            "\titers: 100, epoch: 9 | loss: 0.2042920\n",
            "\tspeed: 17.1130s/iter; left time: 107144.3864s\n",
            "\titers: 200, epoch: 9 | loss: 0.1953745\n",
            "\tspeed: 17.4152s/iter; left time: 107294.8493s\n",
            "\titers: 300, epoch: 9 | loss: 0.1823893\n",
            "\tspeed: 17.7162s/iter; left time: 107377.8581s\n",
            "\titers: 400, epoch: 9 | loss: 0.2302854\n",
            "\tspeed: 18.0199s/iter; left time: 107416.6967s\n",
            "\titers: 500, epoch: 9 | loss: 0.1972172\n",
            "\tspeed: 18.3235s/iter; left time: 107394.3170s\n",
            "Epoch: 9 cost time: 162.7936520576477\n",
            "Epoch: 9, Steps: 530 | Train Loss: 0.2048716 Vali Loss: 0.1654781 Test Loss: 0.1957681\n",
            "EarlyStopping counter: 3 out of 3\n",
            "Early stopping\n",
            ">>>>>>>testing : Linear_PatchTST_Model-6_ECL_ftM_sl720_ll48_pl720_dm512_nh8_el2_dl1_df2048_atprob_fc3_ebtimeF_dtTrue_mxNone_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 4541\n",
            "mse:0.1964065283536911, mae:0.2939644455909729, rse:0.4423035681247711\n",
            "Length of train/test for pred length {} : {} sec or {} mins  720 1968.367773771286 32.806129562854764\n",
            "Time elapsed (s): 6915.235647916794 \n",
            "Time elapsed (mins): 115.2539274652799 \n",
            "Time elapsed (hrs): 1.9208987910879984\n"
          ]
        }
      ],
      "source": [
        "# run the full test - input the model name, data name, multi test and preds \n",
        "run_test_colab(model_name='Linear_PatchTST', data_name='ECL', multi_test=True, multi_pred=[96, 192, 336, 720]) #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp_lKJj0nJk6"
      },
      "source": [
        "\n",
        "run_test(model_name='DLinear', single_pred=96)\n",
        "\n",
        "--model_name\t- * default DLinear options below\n",
        "\n",
        "--data_name \t- optional default ECL, options below\n",
        "\n",
        "--seq_len\t- optional default 96\n",
        "\n",
        "--target \t- optional default None- will give the one based on the dataset(last col in dataset)\n",
        "\n",
        "--single_pred\t- * default 96\n",
        "\n",
        "--multi_test \t- True/ False\n",
        "\n",
        "--multi_pred \t- optional default if True above [96, 192, 336, 720]\n",
        "\n",
        "Model_names:\n",
        "Informer \t: Model-1\n",
        "\n",
        "PatchTST \t: Model-2\n",
        "\n",
        "DLinear \t: Model-3\n",
        "\n",
        "NLinear \t: Model-4\n",
        "\n",
        "FEDformer \t: Model-5\n",
        "\n",
        "Linear_PatchTST : Model-6\n",
        "\n",
        "PatchFED \t: Model-7\n",
        "\n",
        "RevIN_PatchTST \t: Model-8\n",
        "\n",
        "RevIN_Linear \t: Model-9\n",
        "\n",
        "\n",
        "\n",
        "Data_names:\n",
        "\n",
        "ECL\n",
        "\n",
        "PJM"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
